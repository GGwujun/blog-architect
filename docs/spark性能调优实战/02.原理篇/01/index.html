<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-architect/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-architect";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>03 | RDD：为什么你必须要理解弹性分布式数据集？ - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/spark性能调优实战/02.原理篇/01" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a aria-current="page" class="active" href="/blog-architect/spark性能调优实战">spark性能调优实战</a></li></ul></span><span>架构师<ul><li><a href="/blog-architect/设计模式之美">设计模式之美</a></li><li><a href="/blog-architect/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-architect/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-architect/说透中台">说透中台</a></li><li><a href="/blog-architect/oauth2.0实战课">oauth2.0实战课</a></li><li><a href="/blog-architect/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-architect/即时消息技术剖析与实战">即时消息技术剖析与实战</a></li><li><a href="/blog-architect/如何设计一个秒杀系统">如何设计一个秒杀系统</a></li><li><a href="/blog-architect/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-architect/性能优化高手课">性能优化高手课</a></li><li><a href="/blog-architect/性能工程高手课">性能工程高手课</a></li><li><a href="/blog-architect/手把手带你搭建秒杀系统">手把手带你搭建秒杀系统</a></li><li><a href="/blog-architect/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-architect/推荐系统三十六式">推荐系统三十六式</a></li><li><a href="/blog-architect/检索技术核心20讲">检索技术核心20讲</a></li><li><a href="/blog-architect/软件设计之美">软件设计之美</a></li><li><a href="/blog-architect/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect/高楼的性能工程实战课">高楼的性能工程实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a aria-current="page" class="active" href="/blog-architect/spark性能调优实战">spark性能调优实战</a></li></ul></li><li>架构师<ul><li><a href="/blog-architect/设计模式之美">设计模式之美</a></li><li><a href="/blog-architect/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-architect/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-architect/说透中台">说透中台</a></li><li><a href="/blog-architect/oauth2.0实战课">oauth2.0实战课</a></li><li><a href="/blog-architect/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-architect/即时消息技术剖析与实战">即时消息技术剖析与实战</a></li><li><a href="/blog-architect/如何设计一个秒杀系统">如何设计一个秒杀系统</a></li><li><a href="/blog-architect/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-architect/性能优化高手课">性能优化高手课</a></li><li><a href="/blog-architect/性能工程高手课">性能工程高手课</a></li><li><a href="/blog-architect/手把手带你搭建秒杀系统">手把手带你搭建秒杀系统</a></li><li><a href="/blog-architect/技术与商业案例解读">技术与商业案例解读</a></li><li><a href="/blog-architect/推荐系统三十六式">推荐系统三十六式</a></li><li><a href="/blog-architect/检索技术核心20讲">检索技术核心20讲</a></li><li><a href="/blog-architect/软件设计之美">软件设计之美</a></li><li><a href="/blog-architect/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect/高楼的性能工程实战课">高楼的性能工程实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-architect/spark性能调优实战">spark性能调优实战</a></li><li><a href="/blog-architect/spark性能调优实战/01.课前必学">01.课前必学</a><ul><li><a href="/blog-architect/spark性能调优实战/01.课前必学/01"><span>开篇词 | Spark性能调优，你该掌握这些“套路”</span></a></li><li><a href="/blog-architect/spark性能调优实战/01.课前必学/02"><span>01 | 性能调优的必要性：Spark本身就很快，为啥还需要我调优？</span></a></li><li><a href="/blog-architect/spark性能调优实战/01.课前必学/03"><span>02 | 性能调优的本质：调优的手段五花八门，该从哪里入手？</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-architect/spark性能调优实战/02.原理篇">02.原理篇</a><ul><li><a aria-current="page" class="active" href="/blog-architect/spark性能调优实战/02.原理篇/01"><span>03 | RDD：为什么你必须要理解弹性分布式数据集？</span></a></li><li><a href="/blog-architect/spark性能调优实战/02.原理篇/02"><span>04 | DAG与流水线：到底啥叫“内存计算”？</span></a></li><li><a href="/blog-architect/spark性能调优实战/02.原理篇/03"><span>05 | 调度系统：“数据不动代码动”到底是什么意思？</span></a></li><li><a href="/blog-architect/spark性能调优实战/02.原理篇/04"><span>06 | 存储系统：空间换时间，还是时间换空间？</span></a></li><li><a href="/blog-architect/spark性能调优实战/02.原理篇/05"><span>07 | 内存管理基础：Spark如何高效利用有限的内存空间？</span></a></li></ul></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇">03.通用性能调优篇</a><ul><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/01"><span>08 | 应用开发三原则：如何拓展自己的开发边界？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/02"><span>09 | 调优一筹莫展，配置项速查手册让你事半功倍！（上）</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/03"><span>10 | 调优一筹莫展，配置项速查手册让你事半功倍！（下）</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/04"><span>11 | 为什么说Shuffle是一时无两的性能杀手？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/05"><span>12 | 广播变量（一）：克制Shuffle，如何一招制胜！</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/06"><span>13 | 广播变量（二）：如何让Spark SQL选择Broadcast Joins？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/07"><span>14 | CPU视角：如何高效地利用CPU？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/08"><span>15 | 内存视角（一）：如何最大化内存的使用效率？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/09"><span>16 | 内存视角（二）：如何有效避免Cache滥用？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/10"><span>17 | 内存视角（三）：OOM都是谁的锅？怎么破？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/11"><span>18 | 磁盘视角：如果内存无限大，磁盘还有用武之地吗？</span></a></li><li><a href="/blog-architect/spark性能调优实战/03.通用性能调优篇/12"><span>19 | 网络视角：如何有效降低网络开销？</span></a></li></ul></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇">04.SparkSQL性能调优篇</a><ul><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/01"><span>20 | RDD和DataFrame：既生瑜，何生亮？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/02"><span>21 | Catalyst逻辑计划：你的SQL语句是怎么被优化的？（上）</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/03"><span>22 | Catalyst物理计划：你的SQL语句是怎么被优化的（下）？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/04"><span>23 | 钨丝计划：Tungsten给开发者带来了哪些福报？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/05"><span>24 | Spark 3.0（一）：AQE的3个特性怎么才能用好？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/06"><span>25 | Spark 3.0（二）：DPP特性该怎么用？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/07"><span>26 | Join Hints指南：不同场景下，如何选择Join策略？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/08"><span>27 | 大表Join小表：广播变量容不下小表怎么办？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/09"><span>28 | 大表Join大表（一）：什么是“分而治之”的调优思路？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/10"><span>29 | 大表Join大表（二）：什么是负隅顽抗的调优思路？</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/11"><span>30| 应用开发：北京市小客车（汽油车）摇号趋势分析</span></a></li><li><a href="/blog-architect/spark性能调优实战/04.spark-sql性能调优篇/12"><span>31 | 性能调优：手把手带你提升应用的执行性能</span></a></li></ul></li><li><a href="/blog-architect/spark性能调优实战/05.特别放送">05.特别放送</a><ul><li><a href="/blog-architect/spark性能调优实战/05.特别放送/01"><span>Spark UI（上）| 深入解读Spark作业的“体检报告”</span></a></li><li><a href="/blog-architect/spark性能调优实战/05.特别放送/02"><span>Spark UI（下）：深入解读Spark作业的“体检报告”</span></a></li></ul></li><li><a href="/blog-architect/spark性能调优实战/06.结束语">06.结束语</a><ul><li><a href="/blog-architect/spark性能调优实战/06.结束语/01"><span>期末考试 | “Spark性能调优”100分试卷等你来挑战！</span></a></li><li><a href="/blog-architect/spark性能调优实战/06.结束语/02"><span>结束语 | 在时间面前，做一个笃定学习的人</span></a></li></ul></li><li><a href="/blog-architect/spark性能调优实战/summary">spark性能调优实战</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="RDD为何如此重要" data-depth="2"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#rdd为何如此重要"><span>RDD为何如此重要</span></a></li><li title="深入理解RDD" data-depth="2"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#深入理解rdd"><span>深入理解RDD</span></a></li><li title="从薯片的加工流程看RDD" data-depth="3"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#从薯片的加工流程看rdd"><span>从薯片的加工流程看RDD</span></a></li><li title="RDD的核心特征和属性" data-depth="3"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#rdd的核心特征和属性"><span>RDD的核心特征和属性</span></a></li><li title="小结" data-depth="2"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#小结"><span>小结</span></a></li><li title="每日一练" data-depth="2"><a href="/blog-architect/spark性能调优实战/02.原理篇/01#每日一练"><span>每日一练</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="03--rdd为什么你必须要理解弹性分布式数据集"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#03--rdd为什么你必须要理解弹性分布式数据集"><span class="icon icon-link"></span></a>03 | RDD：为什么你必须要理解弹性分布式数据集？</h1><p>你好，我是吴磊。</p><p>从今天开始，我们进入原理篇的学习。我会以性能调优为导向，给你详细讲讲Spark中的核心概念RDD和DAG，以及重要组件调度系统、存储系统和内存管理。这节课，咱们先来说说RDD。</p><p>RDD可以说是Spark中最基础的概念了，使用Spark的开发者想必对RDD都不陌生，甚至提起RDD，你的耳朵可能都已经听出茧子了。不过，随着Spark开发API的演进和发展，现在上手开发基本都是DataFrame或Dataset API。所以很多初学者会认为，“反正RDD API基本都没人用了，我也没必要弄明白RDD到底是什么。”</p><p>真的是这样的吗？当然不是。</p><h2 id="rdd为何如此重要"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#rdd为何如此重要"><span class="icon icon-link"></span></a>RDD为何如此重要</h2><p>首先，RDD作为Spark对于分布式数据模型的抽象，是构建Spark分布式内存计算引擎的基石。很多Spark核心概念与核心组件，如DAG和调度系统都衍生自RDD。<strong>因此，深入理解RDD有利于你更全面、系统地学习Spark的工作原理。</strong></p><p>其次，尽管RDD API使用频率越来越低，绝大多数人也都已经习惯于DataFrame和Dataset API，但是，无论采用哪种API或是哪种开发语言，你的应用在Spark内部最终都会转化为RDD之上的分布式计算。换句话说，<strong>如果你想要在运行时判断应用的性能瓶颈，前提是你要对RDD足够了解</strong>。还记得吗？定位性能瓶颈是Spark性能调优的第一步。</p><p>不仅如此，对于RDD不求甚解还有可能带来潜在的性能隐患，接下来，我们就从一个反例入手，一起来分析一下。</p><p>还记得，我们在第1讲中讲过的数据过滤与聚合的反例吗？通过这个例子我们明白了性能调优的必要性。那这个例子和RDD有什么关系呢？</p><p>别着急，我们先来回顾一下这个案例中的代码实现，去挖掘开发者采用这种实现方式的深层原因。</p><div class="__dumi-default-code-block"><pre class="prism-code language-unknown"><button class="__dumi-default-icon __dumi-default-code-block-copy-btn" data-status="ready"></button><div class="token-line"><span class="token plain">//实现方案1 —— 反例</span></div><div class="token-line"><span class="token plain">    def createInstance(factDF: DataFrame, startDate: String, endDate: String): DataFrame = {</span></div><div class="token-line"><span class="token plain">    val instanceDF = factDF</span></div><div class="token-line"><span class="token plain">        .filter(col(&quot;eventDate&quot;) &gt; lit(startDate) &amp;&amp; col(&quot;eventDate&quot;) &lt;= lit(endDate))</span></div><div class="token-line"><span class="token plain">        .groupBy(&quot;dim1&quot;, &quot;dim2&quot;, &quot;dim3&quot;, &quot;event_date&quot;)</span></div><div class="token-line"><span class="token plain">        .agg(&quot;sum(value) as sum_value&quot;)</span></div><div class="token-line"><span class="token plain">    instanceDF</span></div><div class="token-line"><span class="token plain">    }</span></div><div class="token-line"><span class="token plain">     </span></div><div class="token-line"><span class="token plain">    pairDF.collect.foreach{</span></div><div class="token-line"><span class="token plain">    case (startDate: String, endDate: String) =&gt;</span></div><div class="token-line"><span class="token plain">        val instance = createInstance(factDF, startDate, endDate)</span></div><div class="token-line"><span class="token plain">        val outPath = s&quot;${rootPath}/endDate=${endDate}/startDate=${startDate}&quot;</span></div><div class="token-line"><span class="token plain">        instance.write.parquet(outPath)</span></div><div class="token-line"><span class="token plain">    }</span></div></pre></div><p>在这段代码中，createInstance的主要逻辑是按照时间条件对factDF进行过滤，返回汇总的业务统计量，然后pairDF循环遍历每一对开始时间和结束时间，循环调用createInstance获取汇总结果并落盘。我们在<a target="_blank" rel="noopener noreferrer" href="https://time.geekbang.org/column/article/352035">第1课<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>中分析过，这份代码的主要问题在于囊括上千万行数据的factDF被反复扫描了几百次，而且是全量扫描，从而拖垮了端到端的执行性能。</p><p>那么，我们不禁要问：开发者究竟为什么会想到用这种低效的方式去实现业务逻辑呢？或者说，是什么内驱因素让开发者自然而然地采用这种实现方式呢？</p><p>让我们跳出Spark、跳出这个专栏，把自己置身于一间教室内：黑板前，老师正在讲解《XX语言编程》，旁边是你的同学，他边听老师讲课，边翻看着桌上的课本。这个场景熟不熟悉？亲不亲切？回想一下，老师讲的、书本上教的和我们示例中的代码，是不是极其类似？</p><p>没错！我们的大脑，已经习惯了for循环，习惯了用函数处理变量、封装计算逻辑，习惯了面向过程的编程模式。在分布式计算出现以前，我们都是这么开发的，老师也是这么讲的，书本上也是这么教的，没毛病。</p><p>因此我认为，开发者之所以会选择上面的实现方式，根本原因在于他把factDF当成了一个普通变量，一个与createInstance函数中startDate、endDate同等地位的形参，他并没有意识到，factDF实际上是一个庞大的、横跨所有计算节点的分布式数据集合，更没有意识到，在分布式运行环境中，外面的for循环会导致这个庞大的数据集被反复地全量扫描。</p><p>这种对于分布式计算认知方面的缺失，究其缘由，还是我们对Spark核心概念RDD的理解不够透彻。所以你看，深入理解RDD还是很有必要的，<strong>对于RDD一知半解，极有可能在应用开发的过程中，不知不觉地留下潜在的性能隐患</strong>。</p><h2 id="深入理解rdd"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#深入理解rdd"><span class="icon icon-link"></span></a>深入理解RDD</h2><p>既然RDD如此重要，它究竟是什么呢？2010年，在一个夜黑风高的夜晚，Matei等人发表了一篇名为《Spark: Cluster Computing with Working Sets》的论文并首次提出了RDD的概念。RDD，全称Resilient Distributed Datasets，翻译过来就是弹性分布式数据集。本质上，它是对于数据模型的抽象，用于囊括所有内存中和磁盘中的分布式数据实体。</p><p>如果就这么从理论出发、照本宣科地讲下去，未免过于枯燥、乏味、没意思！不如，我先来给你讲个故事。</p><h3 id="从薯片的加工流程看rdd"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#从薯片的加工流程看rdd"><span class="icon icon-link"></span></a>从薯片的加工流程看RDD</h3><p>在很久很久以前，有个生产桶装薯片的工坊，工坊的规模较小，工艺也比较原始。为了充分利用每一颗土豆、降低生产成本，工坊使用 3 条流水线来同时生产 3 种不同尺寸的桶装薯片。3 条流水线可以同时加工 3 颗土豆，每条流水线的作业流程都是一样的，分别是清洗、切片、烘焙、分发和装桶。其中，分发环节用于区分小、中、大号 3 种薯片，3种不同尺寸的薯片分别被发往第1、2、3条流水线。具体流程如下图所示。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimage3c6e3c7ff059e50f3dc70bf4yy082c31956e.a505ff44.jpg" alt="" title="RDD的生活化类比"/></p><p>看得出来，这家工坊制作工艺虽然简单，倒也蛮有章法。从头至尾，除了分发环节，3 条流水线没有任何交集。在分发环节之前，每条流水线都是专心致志、各顾各地开展工作：把土豆食材加载到流水线上，再进行清洗、切片、烘焙；在分发环节之后，3 条流水线也是各自装桶，互不干涉、互不影响。流水线的作业方式提供了较强的容错能力，如果某个加工环节出错，工人们只需要往出错的流水线上重新加载一颗新的土豆，整个流水线就能够恢复生产。</p><p>好了，故事讲完了。如果我们把每一条流水线看作是分布式运行环境的计算节点，用薯片生产的流程去类比Spark分布式计算，会有哪些有趣的发现呢？</p><p>仔细观察，我们发现：<strong>刚从地里挖出来的土豆食材、清洗过后的干净土豆、生薯片、烤熟的薯片，流水线上这些食材的不同形态，就像是Spark中RDD对于不同数据集合的抽象</strong>。</p><p>沿着流水线的纵深方向，也就是图中从左向右的方向，每一种食材形态都是在前一种食材之上用相应的加工方法进行处理得到的。<strong>每种食材形态都依赖于前一种食材，这就像是RDD中dependencies属性记录的依赖关系，而不同环节的加工方法，对应的刚好就是RDD的compute属性。</strong></p><p>横看成岭侧成峰，再让我们从横向的角度来重新审视上面的土豆加工流程，也就是图中从上至下的方向，让我们把目光集中在流水线开端那3颗带泥的土豆上。这3颗土豆才从地里挖出来，是原始的食材形态，正等待清洗。如图所示，我们把这种食材形态标记为potatosRDD，那么，<strong>这里的每一颗土豆就是RDD中的数据分片，3颗土豆一起对应的就是RDD的partitions属性</strong>。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimagea2c8a2f8bc7bf10c31fedb85196f33f44fc8.28db7075.jpg" alt=""/></p><p>带泥土豆经过清洗、切片和烘焙之后，按照大小个儿被分发到下游的3条流水线上，这3条流水线上承载的RDD记为shuffledBakedChipsRDD。很明显，这个RDD对于partitions的划分是有讲究的，根据尺寸的不同，即食薯片会被划分到不同的数据分片中。<strong>像这种数据分片划分规则，对应的就是RDD中的partitioner属性。</strong> 在分布式运行环境中，partitioner属性定义了RDD所封装的分布式数据集如何划分成数据分片。</p><p>总的来说，我们发现，薯片生产的流程和Spark分布式计算是一一对应的，一共可以总结为6点：</p><ul><li>土豆工坊的每条流水线就像是分布式环境中的计算节点；</li><li>不同的食材形态，如带泥的土豆、土豆切片、烘烤的土豆片等等，对应的就是RDD；</li><li>每一种食材形态都会依赖上一种形态，如烤熟的土豆片依赖上一个步骤的生土豆切片。这种依赖关系对应的就是RDD中的dependencies属性；</li><li>不同环节的加工方法对应RDD的compute属性；</li><li>同一种食材形态在不同流水线上的具体实物，就是RDD的partitions属性；</li><li>食材按照什么规则被分配到哪条流水线，对应的就是RDD的partitioner属性。</li></ul><p>不知道土豆工坊的类比，有没有帮你逐渐勾勒出RDD的本来面貌呢？话付前言，接下来，咱们来一本正经地聊聊RDD。</p><h3 id="rdd的核心特征和属性"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#rdd的核心特征和属性"><span class="icon icon-link"></span></a>RDD的核心特征和属性</h3><p>通过刚才的例子，我们知道RDD具有4大属性，**分别是partitions、partitioner、dependencies和compute属性。正因为有了这4大属性的存在，让RDD具有分布式和容错性这两大最突出的特性。**要想深入理解RDD，我们不妨从它的核心特性和属性入手。</p><p><strong>首先，我们来看partitions、partitioner属性。</strong></p><p>在分布式运行环境中，RDD封装的数据在物理上散落在不同计算节点的内存或是磁盘中，这些散落的数据被称“数据分片”，RDD的分区规则决定了哪些数据分片应该散落到哪些节点中去。RDD的partitions属性对应着RDD分布式数据实体中所有的数据分片，而partitioner属性则定义了划分数据分片的分区规则，如按哈希取模或是按区间划分等。</p><p>不难发现，partitions和partitioner属性刻画的是RDD在跨节点方向上的横向扩展，所以我们把它们叫做RDD的“横向属性”。</p><p><strong>然后，我们再来说说dependencies和compute属性。</strong></p><p>在Spark中，任何一个 RDD 都不是凭空产生的，每个 RDD 都是基于某种计算逻辑从某个“数据源”转换而来。RDD的dependencies属性记录了生成RDD 所需的“数据源”，术语叫做父依赖（或父RDD），compute方法则封装了从父 RDD到当前RDD转换的计算逻辑。</p><p>基于数据源和转换逻辑，无论RDD有什么差池（如节点宕机造成部分数据分片丢失），在dependencies属性记录的父RDD之上，都可以通过执行compute封装的计算逻辑再次得到当前的RDD，如下图所示。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimagefb91fba28ce0c70b4c5553505911663aa491.8d33f4d5.jpg" alt="" title="基于dependencies和compute属性得到当前RDD"/></p><p>由dependencies和compute属性提供的容错能力，为Spark分布式内存计算的稳定性打下了坚实的基础，这也正是RDD命名中Resilient的由来。接着观察上图，我们不难发现，不同的RDD通过dependencies和compute属性链接在一起，逐渐向纵深延展，构建了一张越来越深的有向无环图，也就是我们常说的DAG。</p><p>由此可见，dependencies属性和compute属性负责RDD在纵深方向上的延展，因此我们不妨把这两个属性称为“纵向属性”。</p><p>总的来说，<strong>RDD的4大属性又可以划分为两类，横向属性和纵向属性。其中，横向属性锚定数据分片实体，并规定了数据分片在分布式集群中如何分布；纵向属性用于在纵深方向构建DAG，通过提供重构RDD的容错能力保障内存计算的稳定性</strong>。</p><p>同时，为了帮助你记忆，我把这4大核心属性的基本概念和分类总结在了如下的表格中，你可以看一看。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimageca1eca6ef660c2b7f3777e244a535020191e.59380266.jpeg" alt=""/></p><p>除此之外，我还想再多说两句。在这节课开头的反例中，我们分析了开发者采用foreach语句循环遍历分布式数据集的深层次原因。<strong>这种不假思索地直入面向过程编程、忽略或无视分布式数据实体的编程模式，我将其称为单机思维模式</strong>。</p><p>在学习了RDD横向的partitions属性和纵向的dependencies属性之后，如果你能把它们牢记于心，那么在频繁调用或引用这个RDD之前，你自然会想到它所囊括的数据集合，很有可能在全节点范围内被反复扫描、反复计算。这种下意识的反思会驱使你尝试探索其他更优的实现方式，从而跳出单机思维模式。因此，<strong>深入理解RDD，也有利于你跳出单机思维模式，避免在应用代码中留下性能隐患</strong>。</p><h2 id="小结"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#小结"><span class="icon icon-link"></span></a>小结</h2><p>今天，我带你学习了RDD的重要性，以及它的2大核心特性和4大属性。</p><p>首先，深入理解RDD对开发者来说有百利而无一害，原因有如下3点：</p><ul><li>Spark很多核心概念都衍生自RDD，弄懂RDD，有利于你全面地学习Spark；</li><li>牢记RDD的关键特性和核心属性，有利于你在运行时更好地定位性能瓶颈，而瓶颈定位，恰恰是性能调优的前提；</li><li><strong>深入理解RDD有利于你跳出单机思维模式，避免在应用代码中留下性能隐患。</strong></li></ul><p>关于RDD的特性与核心属性，只要你把如下2点牢记于心，我相信在不知不觉中你自然会绕过很多性能上的坑：</p><ul><li>横向属性partitions和partitioner锚定数据分片实体，并且规定了数据分片在分布式集群中如何分布；</li><li>纵向属性dependencies和compute用于在纵深方向构建DAG，通过提供重构RDD的容错能力保障内存计算的稳定性。</li></ul><h2 id="每日一练"><a aria-hidden="true" tabindex="-1" href="/blog-architect/spark性能调优实战/02.原理篇/01#每日一练"><span class="icon icon-link"></span></a>每日一练</h2><ol><li><p>在日常的开发工作中，你遇到过“单机思维模式”吗？有哪些呢？</p></li><li><p>除了我们今天讲的4大属性，RDD还有个很重要的属性：preferredLocations。按照经验，你认为在哪些情况下，preferredLocations很重要，会提升I/O效率，又在哪些环境中不起作用呢？为什么？</p></li></ol><p>期待在留言区看到你的思考，也欢迎你分享工作中遇到过的“单机思维模式”，我们下节课见！</p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/spark性能调优实战/02.原理篇/01.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/29 14:47:35</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-architect/umi.ded6fefd.js"></script>
  </body>
</html>
