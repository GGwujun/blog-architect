<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no"
    />
    <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
    <link rel="stylesheet" href="/blog-architect/umi.3ec1f225.css" />
    <script>
      window.routerBase = "/blog-architect";
    </script>
    <script>
      //! umi version: 3.5.41
    </script>
    <script>
      !(function () {
        var e =
            navigator.cookieEnabled && void 0 !== window.localStorage
              ? localStorage.getItem("dumi:prefers-color")
              : "auto",
          o = window.matchMedia("(prefers-color-scheme: dark)").matches,
          t = ["light", "dark", "auto"];
        document.documentElement.setAttribute(
          "data-prefers-color",
          e === t[2] ? (o ? t[1] : t[0]) : t.indexOf(e) > -1 ? e : t[0]
        );
      })();
    </script>
    <title>13 | 经典模型融合办法：线性模型和树模型的组合拳 - 大师兄</title>
  </head>
  <body>
    <div id="root"><div class="__dumi-default-layout" data-route="/推荐系统三十六式/06.原理篇·模型融合/01" data-show-sidemenu="true" data-show-slugs="true" data-site-mode="true" data-gapless="false"><div class="__dumi-default-navbar" data-mode="site"><button class="__dumi-default-navbar-toggle"></button><a class="__dumi-default-navbar-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect/">大师兄</a><nav><div class="__dumi-default-search"><input type="search" class="__dumi-default-search-input" value=""/><ul></ul></div><span>后端开发<ul><li><a href="/blog-architect/spark性能调优实战">spark性能调优实战</a></li></ul></span><span>架构师<ul><li><a href="/blog-architect/设计模式之美">设计模式之美</a></li><li><a href="/blog-architect/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-architect/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-architect/说透中台">说透中台</a></li><li><a href="/blog-architect/oauth2.0实战课">oauth2.0实战课</a></li><li><a href="/blog-architect/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-architect/即时消息技术剖析与实战">即时消息技术剖析与实战</a></li><li><a href="/blog-architect/如何设计一个秒杀系统">如何设计一个秒杀系统</a></li><li><a href="/blog-architect/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-architect/性能优化高手课">性能优化高手课</a></li><li><a href="/blog-architect/性能工程高手课">性能工程高手课</a></li><li><a href="/blog-architect/手把手带你搭建秒杀系统">手把手带你搭建秒杀系统</a></li><li><a href="/blog-architect/技术与商业案例解读">技术与商业案例解读</a></li><li><a aria-current="page" class="active" href="/blog-architect/推荐系统三十六式">推荐系统三十六式</a></li><li><a href="/blog-architect/检索技术核心20讲">检索技术核心20讲</a></li><li><a href="/blog-architect/软件设计之美">软件设计之美</a></li><li><a href="/blog-architect/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect/高楼的性能工程实战课">高楼的性能工程实战课</a></li></ul></span><div class="__dumi-default-navbar-tool"><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "></div></div></div></nav></div><div class="__dumi-default-menu" data-mode="site"><div class="__dumi-default-menu-inner"><div class="__dumi-default-menu-header"><a class="__dumi-default-menu-logo" style="background-image:url(&#x27;/logo.png&#x27;)" href="/blog-architect/"></a><h1>大师兄</h1><p></p></div><div class="__dumi-default-menu-mobile-area"><ul class="__dumi-default-menu-nav-list"><li>后端开发<ul><li><a href="/blog-architect/spark性能调优实战">spark性能调优实战</a></li></ul></li><li>架构师<ul><li><a href="/blog-architect/设计模式之美">设计模式之美</a></li><li><a href="/blog-architect/架构实战案例解析">架构实战案例解析</a></li><li><a href="/blog-architect/许式伟的架构课">许式伟的架构课</a></li><li><a href="/blog-architect/说透中台">说透中台</a></li><li><a href="/blog-architect/oauth2.0实战课">oauth2.0实战课</a></li><li><a href="/blog-architect/从0开始学架构">从0开始学架构</a></li><li><a href="/blog-architect/即时消息技术剖析与实战">即时消息技术剖析与实战</a></li><li><a href="/blog-architect/如何设计一个秒杀系统">如何设计一个秒杀系统</a></li><li><a href="/blog-architect/如何落地业务建模">如何落地业务建模</a></li><li><a href="/blog-architect/性能优化高手课">性能优化高手课</a></li><li><a href="/blog-architect/性能工程高手课">性能工程高手课</a></li><li><a href="/blog-architect/手把手带你搭建秒杀系统">手把手带你搭建秒杀系统</a></li><li><a href="/blog-architect/技术与商业案例解读">技术与商业案例解读</a></li><li><a aria-current="page" class="active" href="/blog-architect/推荐系统三十六式">推荐系统三十六式</a></li><li><a href="/blog-architect/检索技术核心20讲">检索技术核心20讲</a></li><li><a href="/blog-architect/软件设计之美">软件设计之美</a></li><li><a href="/blog-architect/高并发系统设计40问">高并发系统设计40问</a></li><li><a href="/blog-architect/高楼的性能工程实战课">高楼的性能工程实战课</a></li></ul></li></ul><div class="__dumi-default-dark"><div class="__dumi-default-dark-switch "><button title="Dark theme" class="__dumi-default-dark-moon "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3854" width="22" height="22"><path d="M991.816611 674.909091a69.166545 69.166545 0 0 0-51.665455-23.272727 70.795636 70.795636 0 0 0-27.438545 5.585454A415.674182 415.674182 0 0 1 754.993338 698.181818c-209.594182 0-393.472-184.785455-393.472-395.636363 0-52.363636 38.539636-119.621818 69.515637-173.614546 4.887273-8.610909 9.634909-16.756364 14.103272-24.901818A69.818182 69.818182 0 0 0 384.631156 0a70.842182 70.842182 0 0 0-27.438545 5.585455C161.678429 90.298182 14.362065 307.898182 14.362065 512c0 282.298182 238.824727 512 532.38691 512a522.286545 522.286545 0 0 0 453.957818-268.334545A69.818182 69.818182 0 0 0 991.816611 674.909091zM546.679156 954.181818c-248.785455 0-462.941091-192-462.941091-442.181818 0-186.647273 140.637091-372.829091 300.939637-442.181818-36.817455 65.629091-92.578909 151.970909-92.578909 232.727273 0 250.181818 214.109091 465.454545 462.917818 465.454545a488.331636 488.331636 0 0 0 185.181091-46.545455 453.003636 453.003636 0 0 1-393.565091 232.727273z m103.656728-669.323636l-14.266182 83.781818a34.909091 34.909091 0 0 0 50.362182 36.770909l74.775272-39.563636 74.752 39.563636a36.142545 36.142545 0 0 0 16.174546 3.956364 34.909091 34.909091 0 0 0 34.210909-40.727273l-14.289455-83.781818 60.509091-59.345455a35.025455 35.025455 0 0 0-19.223272-59.578182l-83.61891-12.101818-37.376-76.101818a34.56 34.56 0 0 0-62.254545 0l-37.376 76.101818-83.618909 12.101818a34.909091 34.909091 0 0 0-19.246546 59.578182z m70.423272-64.698182a34.280727 34.280727 0 0 0 26.135273-19.083636l14.312727-29.090909 14.336 29.090909a34.257455 34.257455 0 0 0 26.135273 19.083636l32.046546 4.887273-23.272728 22.574545a35.234909 35.234909 0 0 0-10.007272 30.952727l5.46909 32.116364-28.625454-15.127273a34.490182 34.490182 0 0 0-32.302546 0l-28.695272 15.127273 5.469091-32.116364a35.141818 35.141818 0 0 0-9.984-30.952727l-23.272728-22.574545z" p-id="3855"></path></svg></button><button title="Light theme" class="__dumi-default-dark-sun "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="4026" width="22" height="22"><path d="M915.2 476.16h-43.968c-24.704 0-44.736 16-44.736 35.84s20.032 35.904 44.736 35.904H915.2c24.768 0 44.8-16.064 44.8-35.904s-20.032-35.84-44.8-35.84zM512 265.6c-136.704 0-246.464 109.824-246.464 246.4 0 136.704 109.76 246.464 246.464 246.464S758.4 648.704 758.4 512c0-136.576-109.696-246.4-246.4-246.4z m0 425.6c-99.008 0-179.2-80.128-179.2-179.2 0-98.944 80.192-179.2 179.2-179.2S691.2 413.056 691.2 512c0 99.072-80.192 179.2-179.2 179.2zM197.44 512c0-19.84-19.136-35.84-43.904-35.84H108.8c-24.768 0-44.8 16-44.8 35.84s20.032 35.904 44.8 35.904h44.736c24.768 0 43.904-16.064 43.904-35.904zM512 198.464c19.776 0 35.84-20.032 35.84-44.8v-44.8C547.84 84.032 531.84 64 512 64s-35.904 20.032-35.904 44.8v44.8c0 24.768 16.128 44.864 35.904 44.864z m0 627.136c-19.776 0-35.904 20.032-35.904 44.8v44.736C476.096 940.032 492.16 960 512 960s35.84-20.032 35.84-44.8v-44.736c0-24.768-16.064-44.864-35.84-44.864z m329.92-592.832c17.472-17.536 20.288-43.072 6.4-57.024-14.016-14.016-39.488-11.2-57.024 6.336-4.736 4.864-26.496 26.496-31.36 31.36-17.472 17.472-20.288 43.008-6.336 57.024 13.952 14.016 39.488 11.2 57.024-6.336 4.8-4.864 26.496-26.56 31.296-31.36zM213.376 759.936c-4.864 4.8-26.56 26.624-31.36 31.36-17.472 17.472-20.288 42.944-6.4 56.96 14.016 13.952 39.552 11.2 57.024-6.336 4.8-4.736 26.56-26.496 31.36-31.36 17.472-17.472 20.288-43.008 6.336-56.96-14.016-13.952-39.552-11.072-56.96 6.336z m19.328-577.92c-17.536-17.536-43.008-20.352-57.024-6.336-14.08 14.016-11.136 39.488 6.336 57.024 4.864 4.864 26.496 26.56 31.36 31.424 17.536 17.408 43.008 20.288 56.96 6.336 14.016-14.016 11.264-39.488-6.336-57.024-4.736-4.864-26.496-26.56-31.296-31.424z m527.168 628.608c4.864 4.864 26.624 26.624 31.36 31.424 17.536 17.408 43.072 20.224 57.088 6.336 13.952-14.016 11.072-39.552-6.4-57.024-4.864-4.8-26.56-26.496-31.36-31.36-17.472-17.408-43.072-20.288-57.024-6.336-13.952 14.016-11.008 39.488 6.336 56.96z" p-id="4027"></path></svg></button><button title="Default to system" class="__dumi-default-dark-auto "><svg viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="11002" width="22" height="22"><path d="M127.658667 492.885333c0-51.882667 10.24-101.717333 30.378666-149.162666s47.786667-88.064 81.92-122.538667 75.093333-61.781333 122.538667-81.92 96.938667-30.378667 149.162667-30.378667 101.717333 10.24 149.162666 30.378667 88.405333 47.786667 122.88 81.92 61.781333 75.093333 81.92 122.538667 30.378667 96.938667 30.378667 149.162666-10.24 101.717333-30.378667 149.162667-47.786667 88.405333-81.92 122.88-75.093333 61.781333-122.88 81.92-97.28 30.378667-149.162666 30.378667-101.717333-10.24-149.162667-30.378667-88.064-47.786667-122.538667-81.92-61.781333-75.093333-81.92-122.88-30.378667-96.938667-30.378666-149.162667z m329.045333 0c0 130.048 13.994667 244.394667 41.984 343.381334h12.970667c46.762667 0 91.136-9.216 133.461333-27.306667s78.848-42.666667 109.568-73.386667 54.954667-67.242667 73.386667-109.568 27.306667-86.698667 27.306666-133.461333c0-46.421333-9.216-90.794667-27.306666-133.12s-42.666667-78.848-73.386667-109.568-67.242667-54.954667-109.568-73.386667-86.698667-27.306667-133.461333-27.306666h-11.605334c-28.672 123.562667-43.349333 237.909333-43.349333 343.722666z" p-id="11003"></path></svg></button></div></div></div><ul class="__dumi-default-menu-list"><li><a href="/blog-architect/推荐系统三十六式">推荐系统三十六式</a></li><li><a href="/blog-architect/推荐系统三十六式/01.开篇词">01.开篇词</a><ul><li><a href="/blog-architect/推荐系统三十六式/01.开篇词/01"><span>开篇词 | 用知识去对抗技术不平等</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/02.概念篇">02.概念篇</a><ul><li><a href="/blog-architect/推荐系统三十六式/02.概念篇/01"><span>01 | 你真的需要个性化推荐系统吗?</span></a></li><li><a href="/blog-architect/推荐系统三十六式/02.概念篇/02"><span>02 | 个性化推荐系统有哪些绕不开的经典问题？</span></a></li><li><a href="/blog-architect/推荐系统三十六式/02.概念篇/03"><span>03 | 这些你必须应该具备的思维模式</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/03.原理篇·内容推荐">03.原理篇·内容推荐</a><ul><li><a href="/blog-architect/推荐系统三十六式/03.原理篇·内容推荐/01"><span>04 | 画鬼容易画人难：用户画像的“能”和“不能”</span></a></li><li><a href="/blog-architect/推荐系统三十六式/03.原理篇·内容推荐/02"><span>05 | 从文本到用户画像有多远</span></a></li><li><a href="/blog-architect/推荐系统三十六式/03.原理篇·内容推荐/03"><span>06 | 超越标签的内容推荐系统</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/04.原理篇·近邻推荐">04.原理篇·近邻推荐</a><ul><li><a href="/blog-architect/推荐系统三十六式/04.原理篇·近邻推荐/01"><span>07 | 人以群分，你是什么人就看到什么世界</span></a></li><li><a href="/blog-architect/推荐系统三十六式/04.原理篇·近邻推荐/02"><span>08 | 解密“看了又看”和“买了又买”</span></a></li><li><a href="/blog-architect/推荐系统三十六式/04.原理篇·近邻推荐/03"><span>09 | 协同过滤中的相似度计算方法有哪些</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/05.原理篇·矩阵分解">05.原理篇·矩阵分解</a><ul><li><a href="/blog-architect/推荐系统三十六式/05.原理篇·矩阵分解/01"><span>10 | 那些在Netflix Prize中大放异彩的推荐算法</span></a></li><li><a href="/blog-architect/推荐系统三十六式/05.原理篇·矩阵分解/02"><span>11 | Facebook是怎么为十亿人互相推荐好友的</span></a></li><li><a href="/blog-architect/推荐系统三十六式/05.原理篇·矩阵分解/03"><span>12 | 如果关注排序效果，那么这个模型可以帮到你</span></a></li></ul></li><li><a aria-current="page" class="active" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合">06.原理篇·模型融合</a><ul><li><a aria-current="page" class="active" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01"><span>13 | 经典模型融合办法：线性模型和树模型的组合拳</span></a></li><li><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/02"><span>14 | 一网打尽协同过滤、矩阵分解和线性模型</span></a></li><li><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/03"><span>15 | 深度和宽度兼具的融合模型 Wide and Deep</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/07.原理篇·mab问题">07.原理篇·MAB问题</a><ul><li><a href="/blog-architect/推荐系统三十六式/07.原理篇·mab问题/01"><span>16 | 简单却有效的Bandit算法</span></a></li><li><a href="/blog-architect/推荐系统三十六式/07.原理篇·mab问题/02"><span>17 | 结合上下文信息的Bandit算法</span></a></li><li><a href="/blog-architect/推荐系统三十六式/07.原理篇·mab问题/03"><span>18 | 如何将Bandit算法与协同过滤结合使用</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/08.原理篇·深度学习">08.原理篇·深度学习</a><ul><li><a href="/blog-architect/推荐系统三十六式/08.原理篇·深度学习/01"><span>19 | 深度学习在推荐系统中的应用有哪些?</span></a></li><li><a href="/blog-architect/推荐系统三十六式/08.原理篇·深度学习/02"><span>20 | 用RNN构建个性化音乐播单</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/09.原理篇·其他应用算法">09.原理篇·其他应用算法</a><ul><li><a href="/blog-architect/推荐系统三十六式/09.原理篇·其他应用算法/01"><span>21 | 构建一个科学的排行榜体系</span></a></li><li><a href="/blog-architect/推荐系统三十六式/09.原理篇·其他应用算法/02"><span>22 | 实用的加权采样算法</span></a></li><li><a href="/blog-architect/推荐系统三十六式/09.原理篇·其他应用算法/03"><span>23 | 推荐候选池的去重策略</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/10.工程篇·常见架构">10.工程篇·常见架构</a><ul><li><a href="/blog-architect/推荐系统三十六式/10.工程篇·常见架构/01"><span>24 | 典型的信息流架构是什么样的</span></a></li><li><a href="/blog-architect/推荐系统三十六式/10.工程篇·常见架构/02"><span>25 | Netflix个性化推荐架构</span></a></li><li><a href="/blog-architect/推荐系统三十六式/10.工程篇·常见架构/03"><span>26 | 总览推荐架构和搜索、广告的关系</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/11.工程篇·常见模块">11.工程篇·常见模块</a><ul><li><a href="/blog-architect/推荐系统三十六式/11.工程篇·常见模块/01"><span>27 | 巧妇难为无米之炊：数据采集关键要素</span></a></li><li><a href="/blog-architect/推荐系统三十六式/11.工程篇·常见模块/02"><span>28 | 让你的推荐系统反应更快：实时推荐</span></a></li><li><a href="/blog-architect/推荐系统三十六式/11.工程篇·常见模块/03"><span>29 | 让数据驱动落地，你需要一个实验平台</span></a></li><li><a href="/blog-architect/推荐系统三十六式/11.工程篇·常见模块/04"><span>30 | 推荐系统服务化、存储选型及API设计</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/12.工程篇·效果保证">12.工程篇·效果保证</a><ul><li><a href="/blog-architect/推荐系统三十六式/12.工程篇·效果保证/01"><span>31 | 推荐系统的测试方法及常用指标介绍</span></a></li><li><a href="/blog-architect/推荐系统三十六式/12.工程篇·效果保证/02"><span>32 | 道高一尺魔高一丈：推荐系统的攻防</span></a></li><li><a href="/blog-architect/推荐系统三十六式/12.工程篇·效果保证/03"><span>33 | 和推荐系统有关的开源工具及框架介绍</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/13.产品篇">13.产品篇</a><ul><li><a href="/blog-architect/推荐系统三十六式/13.产品篇/01"><span>34 | 推荐系统在互联网产品商业链条中的地位</span></a></li><li><a href="/blog-architect/推荐系统三十六式/13.产品篇/02"><span>35 | 说说信息流的前世今生</span></a></li><li><a href="/blog-architect/推荐系统三十六式/13.产品篇/03"><span>36 | 组建推荐团队及工程师的学习路径</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/14.结束语与参考阅读">14.结束语与参考阅读</a><ul><li><a href="/blog-architect/推荐系统三十六式/14.结束语与参考阅读/01"><span>加餐 | 推荐系统的参考阅读</span></a></li><li><a href="/blog-architect/推荐系统三十六式/14.结束语与参考阅读/02"><span>结束语 | 遇“荐”之后，江湖再见</span></a></li><li><a href="/blog-architect/推荐系统三十六式/14.结束语与参考阅读/03"><span>结课测试 | 推荐系统的这些知识，你都掌握了吗？</span></a></li></ul></li><li><a href="/blog-architect/推荐系统三十六式/summary">推荐系统三十六式</a></li></ul></div></div><ul role="slug-list" class="__dumi-default-layout-toc"><li title="为什么要融合？" data-depth="2"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#为什么要融合"><span>为什么要融合？</span></a></li><li title="“辑度组合”原理" data-depth="2"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#辑度组合原理"><span>“辑度组合”原理</span></a></li><li title="逻辑回归" data-depth="3"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#逻辑回归"><span>逻辑回归</span></a></li><li title="梯度提升决策树GBDT" data-depth="3"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#梯度提升决策树gbdt"><span>梯度提升决策树GBDT</span></a></li><li title="二者结合" data-depth="3"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#二者结合"><span>二者结合</span></a></li><li title="总结" data-depth="2"><a href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#总结"><span>总结</span></a></li></ul><div class="__dumi-default-layout-content"><div class="markdown"><h1 id="13--经典模型融合办法线性模型和树模型的组合拳"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#13--经典模型融合办法线性模型和树模型的组合拳"><span class="icon icon-link"></span></a>13 | 经典模型融合办法：线性模型和树模型的组合拳</h1><p>推荐系统在技术实现上一般划分为三个阶段：挖掘、召回、排序。</p><h2 id="为什么要融合"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#为什么要融合"><span class="icon icon-link"></span></a>为什么要融合？</h2><p>挖掘的工作就是对用户和物品做非常深入的结构化分析，庖丁解牛一样，各个角度各个层面的特征都被呈现出来，并且建好索引，供召回阶段使用，大部分挖掘工作都是离线进行的。</p><p>接下来就是召回，为什么会有召回？因为物品太多了，每次给一个用户计算推荐结果时，如果对全部物品挨个计算，那将是一场灾难，取而代之的是用一些手段从全量的物品中筛选出一部分比较靠谱的。</p><p>最后就是排序，针对筛选出的一部分靠谱的做一个统一的论资排辈，最后这个统一的排序就是今天要讲的主题：融合。</p><p>前面巴拉巴拉说了一段，画成图的话会好理解一些，示意图如下。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimage4adb4ac92e6cd98d597faa130b61edd024db.b4c58cea.png" alt=""/></p><p>为什么要融合呢？这还得倒回去说一说召回是什么，以及这个阶段到底发生了什么？</p><p>在召回阶段，其实就是各种简单的、复杂的推荐算法，比如说基于内容的推荐，会产生一些推荐结果，比如基于物品的协同过滤会产生一些结果，矩阵分解会产生一些结果，等等。</p><p>总之，每种算法都会产生一批推荐结果，一般同时还附带给每个结果产生一个推荐分数，是各自算法给出来的。</p><p>于是问题就来了，这些不同算法产生的推荐分数，最后要一起排个先后，难道依据各自的分数吗？</p><p>这样是不行的，为什么？有几个原因：</p><ol><li>有个算法可能只给出结果，不给分数，比如用决策树产生一些推荐结果；</li><li>每种算法给出结果时如果有分数，分数的范围不一定一样，所以不能互相比较，大家各自家庭背景不一样；</li><li>即使强行把所有分数都归一化，仍然不能互相比较，因为产生的机制不同，有的可能普遍偏高，有的可能普遍偏低。</li></ol><p>既然来自各个地方的状元凑在一起，谁也不服谁，那只能再举行一次入学考试了，这个入学考试就是融合模型。也就是，不同算法只负责推举出候选结果，真正最终是否推荐给用户，由另一个统一的模型说了算，这个就叫做模型的融合。</p><p>模型融合的作用除了统一地方军阀，还有集中提升效果的作用。在机器学习中，有专门为融合而生的集成学习思想。</p><p>今天要讲的一个典型的模型融合方案是：逻辑回归和梯度提升决策树组合，我可以给它取个名字叫做“辑度组合”。</p><h2 id="辑度组合原理"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#辑度组合原理"><span class="icon icon-link"></span></a>“辑度组合”原理</h2><p>在推荐系统的模型融合阶段，就要以产品目标为导向。举个简单的例子，信息流推荐，如果以提高CTR为目标，则融合模型就要把预估CTR作为本职工作，这个工作谁最能胜任呢，一直以来就是逻辑回归。</p><p>下面，我就来简单介绍一些常见的逻辑回归。</p><h3 id="逻辑回归"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#逻辑回归"><span class="icon icon-link"></span></a>逻辑回归</h3><p>CTR预估就是在推荐一个物品之前，预估一下用户点击它的概率有多大，再根据这个预估的点击率对物品排序输出。</p><p>逻辑回归常常被选来执行这个任务，它的输出值范围就是0到1之间，刚好满足点击率预估的输出，这是一个基础。因为逻辑回归是广义线性模型，相比于传统线性模型，在线性模型基础上增加了sigmoid函数。</p><p>下面就简单说说，逻辑回归如何做CTR预估？</p><p>我还是按照一直以来的套路来讲，先讲它在真正使用时怎么做的，再一步步往回看怎么得到所需要的条件。</p><p>在对召回阶段不同算法给出的候选物品计算CTR预估时，需要两个东西：</p><ol><li>特征；</li><li>权重。</li></ol><p>第一个是特征，就是用量化、向量的方式把一个用户和一个物品的成对组合表示出来。这里说的量化方式包括两种：实数和布尔。实数好理解，比如一个用户的年龄，一个用户平均在某个品类上每个月的开销，类似等等。</p><p>布尔，就是取值0或者1，针对两种类别形式的，比如用户所在的省、市，当时是白天还是晚上，物品的每一个标签。</p><p>用户和每一个候选物品都组一下CP，然后以这种特征化的方式表达出来，就可以计算了，否则类别形式的字段不能直接参与计算。</p><p>第二个是权重，每个特征都有一个权重，权重就是特征的话事权。在这场决定哪些物品最终有机会能走到前台的选秀过程中，用户和物品这对CP的所有特征都有投票权，只是同人不同命，每个特征的权重不一样，对最终计算CTR影响有大有小。</p><p>这个权重就很重要了，显然不能由愚蠢的人类来指定，需要模型自主从大量的历史数据中学习得到。</p><p>有了特征，它是一个向量，假如把它叫做x；还有特征的权重，也是一个维度和特征一样的向量，假如叫做w。</p><p>我们通过对x和w做点积计算，就得到了一个传统线性模型的输出，再用sigmoid函数对这个值做一个变换，就得到一个0到1之间的值，也就是预估的CTR。</p><p>这里所说的sigmoid函数长这个样子：</p><p>$$\sigma(w\times<!-- -->{<!-- -->x<!-- -->}<!-- -->) = \frac<!-- -->{<!-- -->1<!-- -->}<!-- -->{<!-- -->1+e^<!-- -->{<!-- -->-w\times<!-- -->{<!-- -->x<!-- -->}<!-- -->}<!-- -->}<!-- -->$$</p><p>这个函数曲线如图所示。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimaged53dd5aef83fc6693d22554778c8133bfb3d.d10485c6.png" alt=""/></p><p>那看上去其实要做的就是两件事了：搞特征、学权重。</p><p>事实上的确如此，甚至前者占据更多的时间。逻辑回归特特征的取值都要求要在0到1之间。</p><p>甚至在一些领域，比如搜索广告，特征全都是布尔取值，只有出现和不出现两种，一旦遇到实数取值的特征，就将它划分成多个区间段，也变成了布尔取值。</p><p>除此之外，由于逻辑回归是广义线性模型，所谓广义就是因为加了sigmoid函数，所以很多非线性关系它无能为力。</p><p>比如说，有一天你发现“ID为233的用户喜欢买各种钢笔”这个事实，它可以有两个特征组合出来，一个是“ID为233”，是一个布尔特征，另一个是“物品为钢笔”，也是一个布尔特征，显然构造一个新特征，叫做“ID为233且物品为钢笔”。</p><p>只有两个原始特征都取值为1时，这个构造出的特征才会取值为1，这种组合就是非线性，逻辑回归本身对两个原始特征仅仅是线性加权，并不能很好地刻画这个组合关系，非得组合才能助它一臂之力。</p><p>类似这样的工作，行话都叫做特征工程，刚才举例所说的特征组合叫做二阶组合，还有三阶组合，只要你高兴，也没人拦着你搞四阶组合。</p><p>但是要注意，特征组合的难点在于：组合数目非常庞大，而且并不是所有组合都有效，只有少数组合有效。</p><p>需要不断去弄脏双手，脚上沾泥地从数据中发现新的、有效的特征及特征组合。</p><p>特征工程+线性模型，是模型融合、CTR预估等居家旅行必备。</p><p>权重那部分就是老生常谈了，简单说就是你准备好样本，喂给优化算法，优化算法再挤出新鲜的权重。</p><p>权重的学习主要看两个方面：损失函数的最小化，就是模型的偏差是否足够小；另一个就是模型的正则化，就是看模型的方差是否足够小；都是希望模型能够有足够的生命力，在实际生产线上最好能和实验阶段表现一样好。</p><p>除了要学习出偏差和方差都较小的模型，还需要能够给工程上留出很多余地，具体来说就是两点，一个是希望越多权重为0越好，权重为0称之为稀疏，可以减小很多计算复杂度，并且模型更简单，方差那部分会可控。</p><p>另一个是希望能够在线学习这些权重，用户源源不断贡献他们的行为，后台就会源源不断地更新权重，这样才能实现生命的大和谐。</p><p>要学习逻辑回归的权重，经典的方法如梯度下降一类，尤其是随机梯度下降，这在前面讲矩阵分解时已经提到过，可以实现在实时数据流情形下，更新逻辑回归的权重，每一个样本更新一次。</p><p>但是随机梯度下降常被人诟病的是，它什么也表现不好，很难得到稀疏的模型，效果收敛得也很慢。</p><p>也就是模型预测结果在通往真正想要到达的靶心路上看上去像是喝醉了酒一样，歪歪斜斜，像是很随机，但是趋势上还是在朝损失函数下降的方向。</p><p>后来Google在2013年KDD上发表了新的学习算法：FTRL，一种结合了L1正则和L2正则的在线优化算法，现在各家公司都采用了这个算法。</p><p>这里也顺便提一句，这个专栏重点讲解的是推荐系统落地会用到的东西，尽量通俗易懂。如果深入到机器学习和人工智能其他分支，可以参考极客时间上洪亮劼老师的“AI技术内参”专栏。</p><p>对于我给你讲过的原理，希望可以让你有个直观的理解，在专栏结束后的图书出版计划中，我会在书中更加细致深入地讲原理，就有更多的代码和公式。</p><h3 id="梯度提升决策树gbdt"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#梯度提升决策树gbdt"><span class="icon icon-link"></span></a>梯度提升决策树GBDT</h3><p>前面提到，特征组合又能有效表达出数据中的非线性事实，但是发现成本却很高，需要花大量的人力和物力，那么有没有算法能够在这个阶段帮助到你呢？</p><p>答案是，有！就是用树模型。</p><p>树模型，可以理解为苏格拉底式的诘问，想象不断对一个样本提问：是男用户吗？是的话再问：是北上广的用户吗？不是的话则可以问：是月收入小于5000的用户吗？</p><p>这种不断提问按照层级组织起来，每次回答答案不同后再提出不同的问题，直到最后得出最终答案：用户对这个推荐会满意吗？</p><p>这就是树模型。树模型天然就可以肩负起特征组合的任务，从第一个问题开始，也就是树的根节点，到最后得到答案，也就是叶子节点，这一条路径下来就是若干个特征的组合。</p><p>树模型最原始的是决策树，简称DT，先驱们常常发现，把“多个表现”略好于“随机乱猜”的模型以某种方式集成在一起往往出奇效，所以就有树模型的集成模型。最常见的就是随机森林，简称RF，和梯度提升决策树，简称GBDT。</p><p>先讲一下剃度提升决策树的原理。按照其名字，我把它分成两部分：一个是GB，一个是DT。GB是得到集成模型的方案，沿着残差梯度下降的方向构建新的子模型，而DT就是指构建的子模型要用的决策树。</p><p>梯度提升决策树其实本意是用来做回归问题的，怎么回事呢？</p><p>举个例子好了。假如这里有以下这么几条样本。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimage412d41b2d14f5dd93dcac50da314b325642d.218f2843.png" alt=""/></p><p>现在有个任务是根据是否喜欢养花，喜欢打游戏，喜欢帽子来预测年龄，模型就是梯度提升决策树GBDT。假设我们设定好每个子树只有一层，那么三个特征各自按照取值都可以构成两分支的小树枝。</p><p>树根节点为：是否喜欢养花，左分支就是不喜欢，被划分进去的样本有13、14、15，35这四个年龄；右边的就是样本25、49、68、71、73。左边的样本均值是19.25，右边的样本均值是57.2。</p><p>树根节点为：是否喜欢打游戏，左分支是不喜欢，被划分进去就有49，71，73；右边是喜欢，被划分进去的样本有13、14、15、25、35、68。左边的均值是64，右边的均值是28.3。</p><p>树根节点为：是否喜欢帽子，左分支是不喜欢，被划分进去就有14、15、49、71；右边是喜欢，右边是13、25、35、68、73，左边均值是37.25，右边是42.8。</p><p>叶子节点上都是被划分进去的样本年龄均值，也就是预测值。这里是看哪棵树让残差减小最多，分别拿三个方案去预测每个样本，统计累积的误差平方和，三个分别是1993.55、2602、5007.95，于是显然第一棵树的预测结果较好，所以GBDT中第一棵树胜出。</p><p>接下来第二棵树如何生成呢？这里就体现出GBDT和其他提升算法的不同之处了，比如和Ada boost算法不同之处，GBDT用上一棵树去预测所有样本，得到每一个样本的残差，下一棵树不是去拟合样本的目标值，而是去拟合上一棵树的残差。这里，就是去拟合下面这个表格。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimagefcaffc8d3431f6fda7c845fa9c15fa6959af.121a7429.png" alt=""/></p><p>新一轮构建树的过程以最后一列残差为目标。构建过程这里不再赘述，得到第二棵树。如此不断在上一次建树的残差基础上构建新树，直到满足条件后停止。</p><p>在得到所有这些树后，真正使用时，是将它们的预测结果相加作为最终输出结果。这就是GBDT的简单举例。</p><p>这里有两个问题。</p><p>第一个，既然是用来做回归的，上面这个例子也是回归问题，如何把它用来做分类呢？那就是把损失函数从上面的误差平方和换成适合分类的损失函数，例如对数损失函数。</p><p>更新时按照梯度方向即可，上面的误差平方和的梯度就刚好是残差。对于CTR预估这样的二分类任务，可以将损失函数定义为：</p><p>$$-ylog§ - (1-y)log(1-p)$$</p><p>第二个，通常还需要考虑防止过拟合，也就是损失函数汇总需要增加正则项，正则化的方法一般是：限定总的树个数、树的深度、以及叶子节点的权重大小。</p><p>第三个，构建每一棵树时如果遇到实数值的特征，还需要将其分裂成若干区间，分裂指标有很多，可以参考xgboost中的计算分裂点收益，也可以参考决策树所用的信息增益。</p><h3 id="二者结合"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#二者结合"><span class="icon icon-link"></span></a>二者结合</h3><p>前面介绍了逻辑回归LR，以及剃度提升决策树GBDT的原理。实际上可以将两者结合在一起，用于做模型融合阶段的CTR预估。这是Facebook在其广告系统中使用的方法，其中GBDT的任务就是产生高阶特征组合。</p><p>具体的做法是：GBDT产生了N棵树，一条样本来了后，在每一棵树上都会从根节点走到叶子节点，到了叶子节点后，就是1或者0，点或者不点。把每一棵树的输出看成是一个组合特征，取值为0或者1，一共N棵树，每棵树i有 $M_i$ 个叶子就相当于有M种组合，一棵树对应一个one-hot（独热）编码方式，一共就有$\sum_<!-- -->{<!-- -->i=1<!-- -->}<!-- -->^<!-- -->{<!-- -->N<!-- -->}<!-- -->{<!-- -->M_i<!-- -->}<!-- -->$个维度的新特征，作为输入向量进入LR模型，输出最终的结果。</p><p>示意图如下。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimagec657c613b5946ccbfc2c1321bcec4fef5257.feb9168c.png" alt=""/></p><p>每一条样本，样本内容一般是把用户、物品、场景三类特征拼接在一起，先经过N棵GBDT树各自预测一下，给出自己的0或者1的预测结果，接着，这个N个预测结果再作为N个one-hot编码特征拼接成一个向量送入逻辑回归中，产生最终的融合预估结果。</p><p>另外，由于两者结合后用来做推荐系统的模型融合，所以也可以考虑在输入特征中加入各个召回模型产生的分数，也许会有用。</p><p>以上就是咱们的“辑度组合”原理，虽然简单，但在实际应用中非常的有效。</p><h2 id="总结"><a aria-hidden="true" tabindex="-1" href="/blog-architect/推荐系统三十六式/06.原理篇·模型融合/01#总结"><span class="icon icon-link"></span></a>总结</h2><p>今天我主要讲了简单的逻辑回归和梯度提升决策树，两者都是不太复杂的模型。并且无论是逻辑回归，还是梯度提升决策树，都有非常成熟的开源实现，可以很快落地。</p><p>由于篇幅限制，在梯度提升决策树那部分有一些细节被我略过了，你能自己手算出例子中的第二棵树是什么样的吗？欢迎留言一起讨论。感谢你的收听，我们下期再见。</p><p><img src="/blog-architect/static/httpsstatic001geekbangorgresourceimage87b0873b086966136189db14874181823fb0.5a0b85fb.jpg" alt=""/></p></div><div class="__dumi-default-layout-footer-meta"><a target="_blank" rel="noopener noreferrer" href="https://github.com/GGwujun/blog/edit/master/ssrc/推荐系统三十六式/06.原理篇·模型融合/01.md">在 GitHub 上编辑此页<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="__dumi-default-external-link-icon"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a><span data-updated-text="最后更新时间：">2023/9/29 14:47:35</span></div></div></div></div>
	<script>
  window.g_useSSR = true;
  window.g_initialProps = {};
	</script>

    <script>
      (function () {
        if (!location.port) {
          (function (i, s, o, g, r, a, m) {
            i["GoogleAnalyticsObject"] = r;
            (i[r] =
              i[r] ||
              function () {
                (i[r].q = i[r].q || []).push(arguments);
              }),
              (i[r].l = 1 * new Date());
            (a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m);
          })(
            window,
            document,
            "script",
            "//www.google-analytics.com/analytics.js",
            "ga"
          );
          ga("create", "UA-149864185-1", "auto");
          ga("send", "pageview");
        }
      })();
    </script>
    <script src="/blog-architect/umi.ded6fefd.js"></script>
  </body>
</html>
